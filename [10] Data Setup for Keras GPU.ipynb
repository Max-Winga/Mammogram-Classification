{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da12261",
   "metadata": {},
   "source": [
    "# [10] Data Setup for Keras GPU\n",
    "This file functions similarly to \"[0] Data Setup\" but reworked to create images to run into the Keras Model in \"[11] Keras Testing Safe vs Malignant\". The idea was that if I wanted different resolutions of the concat_imgs array I could create them here but it ended up being best for GPU VRAM to just use the lower res (162\\*2, 135) concat images that we've already been using (plus this makes this model more comparable to the others). This means that nothing from this notebook is actually used in the final keras model notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45e3247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T20:52:47.359867Z",
     "start_time": "2022-12-16T20:52:39.618070Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "\n",
    "%matplotlib inline\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import math as m\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "from skimage.transform import resize\n",
    "import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814c5799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T20:52:47.390784Z",
     "start_time": "2022-12-16T20:52:47.360864Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## loading in important variables\n",
    "\n",
    "# Keys\n",
    "with open('OFFICIAL_keys.pkl', 'rb') as f:\n",
    "    keys = pickle.load(f)\n",
    "train_set = keys[:int(0.8*len(keys))]\n",
    "test_set = keys[int(0.8*len(keys)):int(0.9*len(keys))+1]\n",
    "validation_set = keys[int(0.9*len(keys))+1:]\n",
    "\n",
    "# Classifications\n",
    "with open('classifications.pkl', 'rb') as f:\n",
    "    classifications = pickle.load(f)\n",
    "classes = []\n",
    "for i in range(2575):\n",
    "    if classifications[2*i] != classifications[2*i+1]:\n",
    "        print(\"Classification not equal\")\n",
    "    classes.append(classifications[2*i])\n",
    "classes = np.array(classes)\n",
    "\n",
    "# Abnormalities\n",
    "with open('abnormalities.pkl', 'rb') as f:\n",
    "    abnormalities = pickle.load(f)\n",
    "abnorms = []\n",
    "for i in range(2575):\n",
    "    if abnormalities[2*i] != abnormalities[2*i+1]:\n",
    "        print(\"abnormalities not equal\")\n",
    "    abnorms.append(abnormalities[2*i])\n",
    "abnorms = np.array(abnorms)\n",
    "\n",
    "# Orientations\n",
    "with open('orientations.pkl', 'rb') as f:\n",
    "    orientations = pickle.load(f)\n",
    "orientations = np.array(orientations)    \n",
    "scale = (725, 605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aeaf4e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T20:52:47.406741Z",
     "start_time": "2022-12-16T20:52:47.391781Z"
    },
    "code_folding": [
     1,
     6,
     11
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## Functions for rescaling images\n",
    "def rescale_images(input_images, scale):\n",
    "    new_list = []\n",
    "    for image in input_images:\n",
    "        new_list.append(resize(image, scale))\n",
    "    return new_list\n",
    "def np_rescale_images(input_images, scale):\n",
    "    new_array = np.empty((input_images.shape[0], scale[0], scale[1]))\n",
    "    for i, image in enumerate(input_images):\n",
    "        new_array[i] = resize(image, scale)\n",
    "    return new_array\n",
    "def scale_resolution(input_resolution, scale):\n",
    "    yi = input_resolution[0]\n",
    "    xi = input_resolution[1]\n",
    "    pixels = xi*yi\n",
    "    ar = yi/xi\n",
    "    scale_pixels = pixels*scale\n",
    "    xo = (m.sqrt(scale_pixels/ar))\n",
    "    yo = (xo*ar)\n",
    "    return [int(round(yo, 0)), int(round(xo, 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1717bc50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T20:52:47.452618Z",
     "start_time": "2022-12-16T20:52:47.438657Z"
    },
    "code_folding": [
     3
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## This function will splits the images into three groups side view, bottom view, and a combined concatenated view\n",
    "## Takes (index, row, col) returns three np arrays in with images in flattened form -\n",
    "## with shape (index, image)\n",
    "def create_side_bottom_concat(np_imgs, to_print=False, orients=orientations):\n",
    "    side=[]\n",
    "    below=[]\n",
    "    flattened_imgs = np_imgs.reshape(np_imgs.shape[0], np_imgs.shape[1]*np_imgs.shape[2])\n",
    "    if to_print:\n",
    "        print(flattened_imgs.shape)\n",
    "    for i in range(0, flattened_imgs.shape[0]):\n",
    "        if len(orients[i]) == 2:\n",
    "            side.append(flattened_imgs[i])\n",
    "        else:\n",
    "            below.append(flattened_imgs[i])   \n",
    "    side = np.array(side)\n",
    "    below = np.array(below)\n",
    "    concat = np.concatenate((side, below), 1)\n",
    "    if to_print:\n",
    "        print('\\nconcatenated images')\n",
    "        print(f'concat.shape={concat.shape}')\n",
    "        print('\\nside images')\n",
    "        print(f'side.shape={side.shape}')\n",
    "        print('\\nbelow images')\n",
    "        print(f'below.shape={below.shape}')\n",
    "    return side, below, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59aba936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T20:52:47.467579Z",
     "start_time": "2022-12-16T20:52:47.453616Z"
    },
    "code_folding": [
     2
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## This function will flip the right side images to the left for better data workability\n",
    "## Takes (index, row, col) and returns (index, row, col)\n",
    "def flip_list(np_imgs, to_print=False):\n",
    "    flip_list=[]\n",
    "    for q in range(0,len(np_imgs)):\n",
    "        if orientations[q]=='L' or orientations[q]=='FL': #flipping the right images\n",
    "            flip_list.append(np.flip(np_imgs[q],1)) #the integer there is the axis being flipped\n",
    "        else:\n",
    "            flip_list.append(np_imgs[q])\n",
    "    np_flip_list = np.array(flip_list)\n",
    "    \n",
    "    if to_print:\n",
    "        print(f'len(np_imgs)={len(np_imgs)}')\n",
    "        print(f'len(orientations)={len(orientations)}')\n",
    "        print('list of flipped images')\n",
    "        print(f'len(flip_list)={len(flip_list)}')\n",
    "        print(f'flip_list[0].shape={flip_list[0].shape}')\n",
    "        print(f\"np_flip_list.shape={np_flip_list.shape}\")\n",
    "    return np_flip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca2c765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T20:52:47.483536Z",
     "start_time": "2022-12-16T20:52:47.468576Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229, 191]\n"
     ]
    }
   ],
   "source": [
    "## Set New Scale\n",
    "original_scale = [2294, 1914]\n",
    "new_scale = scale_resolution(original_scale, 0.01)\n",
    "print(new_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b848d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:32:54.891090Z",
     "start_time": "2022-12-15T22:32:45.143163Z"
    }
   },
   "outputs": [],
   "source": [
    "## Set Raw Images\n",
    "with open('images.pkl', 'rb') as f:\n",
    "    raw_images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4c8a155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:46:30.077814Z",
     "start_time": "2022-12-15T22:32:59.510734Z"
    }
   },
   "outputs": [],
   "source": [
    "## Scale Raw Images Down and Convert to Numpy Array\n",
    "scaled_images = np.array(rescale_images(raw_images, new_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1662575b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:46:38.436085Z",
     "start_time": "2022-12-15T22:46:36.840336Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save finished input set\n",
    "with open(f'scaled_images_{new_scale[0]}_{new_scale[1]}.pkl', 'wb') as f:\n",
    "    pickle.dump(scaled_images, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8cd6681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:46:40.684597Z",
     "start_time": "2022-12-15T22:46:39.325213Z"
    }
   },
   "outputs": [],
   "source": [
    "del raw_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e161453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T21:57:45.580790Z",
     "start_time": "2022-12-15T21:57:44.655265Z"
    }
   },
   "outputs": [],
   "source": [
    "## Reload Scaled Images\n",
    "with open(f'scaled_images_{new_scale[0]}_{new_scale[1]}.pkl', 'rb') as f:\n",
    "    scaled_images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc2aec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:46:44.643608Z",
     "start_time": "2022-12-15T22:46:44.232170Z"
    }
   },
   "outputs": [],
   "source": [
    "## Flip images to all be on the same side\n",
    "flipped_scaled_images = flip_list(scaled_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf749452",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:46:46.580467Z",
     "start_time": "2022-12-15T22:46:45.831947Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_side, scaled_below, scaled_concat = create_side_bottom_concat(flipped_scaled_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c283a51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:46:47.507011Z",
     "start_time": "2022-12-15T22:46:47.231747Z"
    }
   },
   "outputs": [],
   "source": [
    "del scaled_images, flipped_scaled_images, scaled_side, scaled_below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fac6b9c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:46:49.042925Z",
     "start_time": "2022-12-15T22:46:48.237562Z"
    }
   },
   "outputs": [],
   "source": [
    "## Format Images for Keras\n",
    "scaled_concat = np.reshape(scaled_concat, (scaled_concat.shape[0], new_scale[0]*2, new_scale[1]))\n",
    "scaled_concat = (scaled_concat / 255) - 0.5\n",
    "scaled_concat = np.expand_dims(scaled_concat, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba2ac39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T22:46:51.418099Z",
     "start_time": "2022-12-15T22:46:49.850765Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save finished input set\n",
    "with open(f'finished_concat_images_{new_scale[0]}_{new_scale[1]}.pkl', 'wb') as f:\n",
    "    pickle.dump(scaled_concat, f) "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
